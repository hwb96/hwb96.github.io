<!doctype html>

<html lang="en">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>Han Wenbo</title>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="description" content="The HTML5 Herald" />
<meta name="author" content="HanWenbo" /><link rel="alternate" type="application/rss+xml" href="http://localhost:1313/index.xml" title="Han Wenbo" /><meta property="og:url" content="http://localhost:1313/">
  <meta property="og:site_name" content="Han Wenbo">
  <meta property="og:title" content="Han Wenbo">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Han Wenbo">

<meta name="generator" content="Hugo 0.138.0">
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="http://localhost:1313/js/mathjax-config.js" defer></script>
    <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>

  <link rel="stylesheet" href="http://localhost:1313/css/normalize.min.css" />
  <link rel="stylesheet" href="http://localhost:1313/fontawesome/css/all.min.css" />
  
    
    <link href="//fonts.googleapis.com/css?family=Playfair Display:400,700|PT Serif:400,700|Merriweather:400,700" rel="stylesheet">
  
  
  <link rel="stylesheet" type="text/css" href="http://localhost:1313/css/styles.css" /><link rel='stylesheet' href='http://localhost:1313/css/custom.css'>
</head>

<body>
  <div id="container">
    <header>
      
      <h1>
        <a href="http://localhost:1313/">Han Wenbo</a>
      </h1>

      <ul id="social-media">
             <li>
               <a href="https://github.com/hwb96" title="GitHub">
               <i class="fab fa-github fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://twitter.com/realhanwenbo" title="Twitter">
               <i class="fab fa-twitter fa-lg"></i>
               </a>
             </li>
      </ul>
      
      <p><em>Focus on technology, trends, and their intertwined politics.</em></p>
      
    </header>

    
<nav>
    <ul>
        
        <li>
            <a class="" href="http://localhost:1313/posts/">
                <i class="fa-li fa  fa-lg"></i><span>Posts</span>
            </a>
        </li>
        
        <li>
            <a class="" href="http://localhost:1313/tags">
                <i class="fa-li fa  fa-lg"></i><span>Tags</span>
            </a>
        </li>
        
        <li>
            <a class="" href="http://localhost:1313/about/about-me/">
                <i class="fa-li fa  fa-lg"></i><span>About</span>
            </a>
        </li>
        
    </ul>
</nav>


    <main>




<section id="home">
  <ul>
    
    
    

    <li class="first" >
      <h1><a href="http://localhost:1313/posts/20250210-deepseek-r1-chat-template-change-analysis/" title="R1 系列模型 Chat Template 变更分析与下游解决方案">R1 系列模型 Chat Template 变更分析与下游解决方案</a></h1>
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-02-11T15:24:39&#43;08:00">Feb 11, 2025</time>
        </li>
        
        

        

        <li>4 minute read</li>
    </ul>
</aside>

      
<div class="featured_image">
    <a href="http://localhost:1313/posts/20250210-deepseek-r1-chat-template-change-analysis/" title="R1 系列模型 Chat Template 变更分析与下游解决方案">
        <img src="">
    </a>
</div>


      <p><p>DeepSeek-R1-系列开源模型文件 <code>tokenizer_config.json</code> 的 <code>chat_template</code> 对应的 <a href="https://jinja.palletsprojects.com/en/stable/">Jinja 模板</a> 发生了改变。具体来说，原来的 <code>{'&lt;｜Assistant｜&gt;'}}{% endif %}</code> 变成了 <code>{'&lt;｜Assistant｜&gt;&lt;think&gt;\\n'}}{% endif %}</code>。造成的结果是，本地部署 DeepSeek-R1-系列模型时，输出仅有 <code>&lt;/think&gt;</code>，而没有 <code>&lt;think&gt;</code>，也就是说 <code>&lt;think&gt;</code> 标签现在位于提示词中，而不是生成的内容中。</p></p>
      
      <a href="http://localhost:1313/posts/20250210-deepseek-r1-chat-template-change-analysis/">Read more…</a>
      
    </li>
    

    <li >
      <h1><a href="http://localhost:1313/posts/20250210-vllm-tp-pp-parallelism-explained/" title="vLLM中的并行技术：张量并行(TP)与流水线并行(PP)解析">vLLM中的并行技术：张量并行(TP)与流水线并行(PP)解析</a></h1>
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-02-10T18:43:28&#43;08:00">Feb 10, 2025</time>
        </li>
        
        

        

        <li>One minute read</li>
    </ul>
</aside>

      
<div class="featured_image">
    <a href="http://localhost:1313/posts/20250210-vllm-tp-pp-parallelism-explained/" title="vLLM中的并行技术：张量并行(TP)与流水线并行(PP)解析">
        <img src="">
    </a>
</div>


      <p><p>今天看到有人用vLLM 0.7.1部署r1，TP size 8，PP size 2，忽然想到平时都是用TP，基本上没有用PP，也看到科学空间群里的有人调研使用的命令。然后在公众号，知乎查到的关于TP和PP的说法很多都是错误的，使用perplexity.ai才在reddit和个人网站搜到一些有用的资料，备份复习重温一下吧。</p>
<p><img src="http://localhost:1313/images/20250210-vllm-tp-pp-parallelism-explained/image-20250210182840768.png" alt="image-20250210182840768"></p></p>
      
      <a href="http://localhost:1313/posts/20250210-vllm-tp-pp-parallelism-explained/">Read more…</a>
      
    </li>
    

    <li >
      <h1><a href="http://localhost:1313/posts/20250110-multi-knapsack-nutrition/" title="用多重背包算法解决大模型长距离依赖和数字约束遗忘问题">用多重背包算法解决大模型长距离依赖和数字约束遗忘问题</a></h1>
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-01-10T20:53:39&#43;08:00">Jan 10, 2025</time>
        </li>
        
        

        

        <li>5 minute read</li>
    </ul>
</aside>

      
<div class="featured_image">
    <a href="http://localhost:1313/posts/20250110-multi-knapsack-nutrition/" title="用多重背包算法解决大模型长距离依赖和数字约束遗忘问题">
        <img src="">
    </a>
</div>


      <p><p>最近在做医疗诊断+食谱生成的一个项目，遇到了一个棘手难题：数值敏感度不足，长距离依赖和约束遗忘。 我们需要利用大模型根据患者病情自动生成个性化食谱，首先生成一日营养目标摄入总量，然后生成早餐，中餐，晚餐各个食材的设定目标，结果是各个食材营养摄入总和总是超过总量预设值。LLM虽能生成流畅食谱，却难以精确控制营养素摄入量，为解决此问题，我们提出将食谱生成转化为多重背包问题，利用动态规划算法，在满足每日营养目标（背包容量）的约束下，选择最优菜品组合（价值最大化）。通过检索和约束优化，替代LLM的直接生成。</p></p>
      
      <a href="http://localhost:1313/posts/20250110-multi-knapsack-nutrition/">Read more…</a>
      
    </li>
    

    <li >
      <h1><a href="http://localhost:1313/posts/20250102-ancient-chinese-texts-ai-analysis-family-history-llm-comparison/" title="古籍、AI 与我的家族历史：兼论中外大模型在古文识别中的表现">古籍、AI 与我的家族历史：兼论中外大模型在古文识别中的表现</a></h1>
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-01-02T23:52:40&#43;08:00">Jan 2, 2025</time>
        </li>
        
        

        

        <li>5 minute read</li>
    </ul>
</aside>

      
<div class="featured_image">
    <a href="http://localhost:1313/posts/20250102-ancient-chinese-texts-ai-analysis-family-history-llm-comparison/" title="古籍、AI 与我的家族历史：兼论中外大模型在古文识别中的表现">
        <img src="">
    </a>
</div>


      <p><p>几年前，我得到了一份珍贵的古籍家谱，在我手里待了 30 分钟，这是一本写着我从哪里来的古籍。 高中三年真正培养了我阅读古文的能力，而这种能力将使我受益终身。
趁着我的古文阅读水平还在，我决定借助大模型的力量，将他们翻译出来。</p>
<p>我发现大模型的能力真的参差不齐，美国的大模型识别中文古文的能力让我大吃一惊，比国内任意一家的能力都要好。
我会在文末放出各自的翻译截图，我分别测试了8家大模型，分别是： 国外的：Gemini，Claude，OpenAI ，国内的：通义千问，kimi，deepseek，智谱AI，豆包。</p>
<p>我心目中的对于古籍识别排序的能力排名是这样的：</p>
<p>Gemini &gt; &gt;  通义千问 &gt;  Claude-3.5-Sonnet= gpt-4o= kimi &gt; deepseek v3 = GLM &gt; &gt; 豆包</p>
<p>Gemini 最好，通义千问是接下来的佼佼者。 其他Claude-3.5-Sonnet，gpt-4o，kimi，deepseek v3都是基本还能看下去，但是deepseek v3不懂得古文是从右到左的。 GLM识别重复特别多，但是能识别出里边的内容，豆包就好像是完全在想象。</p>
<p>识别出的内容我放在了附录里。</p></p>
      
      <a href="http://localhost:1313/posts/20250102-ancient-chinese-texts-ai-analysis-family-history-llm-comparison/">Read more…</a>
      
    </li>
    

    <li >
      <h1><a href="http://localhost:1313/posts/20250101-prompt-formatting-impact-on-llm-performance/" title="纯文本、Markdown、YAML和JSON四种提示词样式对模型输出的影响实证">纯文本、Markdown、YAML和JSON四种提示词样式对模型输出的影响实证</a></h1>
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-01-01T11:06:11&#43;08:00">Jan 1, 2025</time>
        </li>
        
        

        

        <li>6 minute read</li>
    </ul>
</aside>

      
<div class="featured_image">
    <a href="http://localhost:1313/posts/20250101-prompt-formatting-impact-on-llm-performance/" title="纯文本、Markdown、YAML和JSON四种提示词样式对模型输出的影响实证">
        <img src="">
    </a>
</div>


      <p><p>我之前的项目实践总是把所有的提示词都设计成Markdown格式，因为我认为这样不仅对大模型友好，对我使用Typora编辑特别长的提示词也十分友好,而且直到现在<a href="https://platform.openai.com/docs/guides/prompt-generation">GPT官方示例</a>也是这样做的。</p>
<p>后来看到<a href="https://x.com/dotey">宝玉</a>分享的<a href="https://baoyu.io/blog/v0-system-prompt-2024">V0提示词</a>，我的直觉告诉我应该试一试XML ，因为我用的提示词生成工具（<a href="https://docs.dify.ai/zh-hans">dify</a>一个内置功能）都是使用这个格式。后来我也频繁使用XML格式，但是到底哪个更好呢？我觉得这篇实证论文挺有参考意义的，因为它给了我使用JSON格式尝试的可能，可惜的是没有XML格式的对比。</p></p>
      
      <a href="http://localhost:1313/posts/20250101-prompt-formatting-impact-on-llm-performance/">Read more…</a>
      
    </li>
    

    <li >
      <h1><a href="http://localhost:1313/posts/20250101-introduction-to-few-shot-learning-best-practices/" title="few-shot 最佳实践指南">few-shot 最佳实践指南</a></h1>
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-01-01T00:56:25&#43;08:00">Jan 1, 2025</time>
        </li>
        
        

        

        <li>2 minute read</li>
    </ul>
</aside>

      
<div class="featured_image">
    <a href="http://localhost:1313/posts/20250101-introduction-to-few-shot-learning-best-practices/" title="few-shot 最佳实践指南">
        <img src="">
    </a>
</div>


      <p><p>在过去的几个月里，我总是习惯于把Few-shot放在系统提示词里。但是我经过使用LangGraph，Dify和其他平台的一些实践，我慢慢地发现，放在QA问答对的几个shot，总是会比放在系统提示词里效果会更好。后来我又开始借鉴在twitter<a href="https://x.com/clusteredbytes/status/1846251848593822051">Rohan</a>的推文使用llamaindex搭建的<a href="https://x.com/llama_index/status/1846351135596335165">动态提示词</a>系统。这并不是熟能生巧，这方面的论文和Medium的文章给了我很大启发，然后我在<a href="https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/">LangChain</a>的官方博客发现了一篇总结得非常好的文章，我一直拖到今天元旦终于闲下来才下定决心写一个翻译稿件。</p></p>
      
      <a href="http://localhost:1313/posts/20250101-introduction-to-few-shot-learning-best-practices/">Read more…</a>
      
    </li>
    
  </ul>
</section>


    <ul class="pagination pagination-default">
      <li class="page-item disabled">
        <a aria-disabled="true" aria-label="First" class="page-link" role="button" tabindex="-1"><span aria-hidden="true">&laquo;&laquo;</span></a>
      </li>
      <li class="page-item disabled">
        <a aria-disabled="true" aria-label="Previous" class="page-link" role="button" tabindex="-1"><span aria-hidden="true">&laquo;</span></a>
      </li>
      <li class="page-item active">
        <a aria-current="page" aria-label="Page 1" class="page-link" role="button">1</a>
      </li>
      <li class="page-item">
        <a href="http://localhost:1313/page/2/" aria-label="Page 2" class="page-link" role="button">2</a>
      </li>
      <li class="page-item">
        <a href="http://localhost:1313/page/2/" aria-label="Next" class="page-link" role="button"><span aria-hidden="true">&raquo;</span></a>
      </li>
      <li class="page-item">
        <a href="http://localhost:1313/page/2/" aria-label="Last" class="page-link" role="button"><span aria-hidden="true">&raquo;&raquo;</span></a>
      </li>
    </ul>



</main>
    <footer>
        <ul>
            <li>
                <h6>
                    Rendered by <a href="https://gohugo.io" title="Hugo">Hugo</a> |
                    <a href="http://localhost:1313/index.xml">Subscribe </a></h6>
            </li>
            
            
        </ul>
    </footer>
</div>
<script src="http://localhost:1313/js/scripts.js"></script>

  


</body>

</html>

